{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "181c36bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Milestone2 ##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "88b8f793",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    custID fraudster\n",
      "0     1083         0\n",
      "1     1137         0\n",
      "2     1207         0\n",
      "3     1240         0\n",
      "4     1389         0\n",
      "..     ...       ...\n",
      "15    1736         0\n",
      "16    1777         0\n",
      "17    1791         0\n",
      "18    1803         0\n",
      "19    1806         0\n",
      "\n",
      "[20 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "### Download and unzip url\n",
    "import numpy as np\n",
    "from zipfile import ZipFile  \n",
    "from urllib.request import urlretrieve\n",
    "import os\n",
    "import pandas as pd\n",
    "from os import mkdir\n",
    "### specifiying url of zip file\n",
    "url = \"https://www.dropbox.com/s/w15ev8i0noj85sa/4269819.zip?dl=1\"\n",
    "csvname = url [-15:-9]\n",
    "# inputFile = \"./DownloadedFile.zip\"\n",
    "# outputDir = \"./DownloadedFile\"\n",
    "\n",
    "INPUT_FILE_SAVE_DIR = \"./DownloadedFile.zip\"\n",
    "OUTPUT_DIR = \"./DownloadFile/\"\n",
    "### put zip file in local directory -- this takes a while.. file is big\n",
    "# urlretrieve(url, inputFile)\n",
    "urlretrieve(url, INPUT_FILE_SAVE_DIR)\n",
    "### unzip contents into output folder -- this takes a while.. file is big\n",
    "# with ZipFile(inputFile) as zipObj:  \n",
    "#     zipObj.extractall(outputDir)\n",
    "with ZipFile(INPUT_FILE_SAVE_DIR) as zipObj:  \n",
    "    zipObj.extractall(OUTPUT_DIR)\n",
    "    \n",
    "\n",
    "### Extract pic names in the folder\n",
    "import os\n",
    "\n",
    "file_list = os.listdir(\"./DownloadedFile\")\n",
    "file_list.sort()\n",
    "\n",
    "# remove .jpg\n",
    "new_list = [s.replace(\".jpg\", \"\") for s in file_list]\n",
    "# print(new_list)\n",
    "\n",
    "### input csv \n",
    "import pandas as pd\n",
    "CustomerList = pd.read_csv(\"./liveCustomerList.csv\") #read the csv file (put 'r' before the path string to address any special characters in the path, such as '\\'). Don't forget to put the file name at the end of the path + \".csv\"\n",
    "CustomerList['firstName'] = CustomerList['firstName'].str.upper()\n",
    "CustomerList['lastName'] = CustomerList['lastName'].str.upper()\n",
    "FraudList = pd.read_csv(\"./liveFraudList.csv\")\n",
    "FraudList[\"fraudster\"] = 'NA'\n",
    "\n",
    "#change custID list to Dataframe\n",
    "#***seperate custID and loginAcct\n",
    "jpg_custID = [s[0:4] for s in file_list]\n",
    "jpg_loginAcct = [s[-10:-4] for s in file_list]\n",
    "\n",
    "# print(jpg_custID)\n",
    "# print(jpg_loginAcct)\n",
    "\n",
    "custID = pd.DataFrame(jpg_custID, columns = ['custID'])\n",
    "loginAcct = pd.DataFrame(jpg_loginAcct, columns = ['loginAcct'])\n",
    "\n",
    "# change datatype\n",
    "custID['custID']=custID['custID'].astype(int)\n",
    "loginAcct['loginAcct']=loginAcct['loginAcct'].astype(int)\n",
    "# print (custID.dtypes)\n",
    "# print(custID)\n",
    "\n",
    "# left join table custID and customerlist\n",
    "custIDname = pd.merge(custID, CustomerList, on='custID', how='left')\n",
    "custIDnameFraud = pd.merge(custIDname, FraudList, on=[\n",
    "        'firstName', 'lastName'], how='left')\n",
    "custIDnameFraud['fraudster'] = custIDnameFraud['fraudster'].fillna(0)\n",
    "\n",
    "# FraudTestOnput.csv\n",
    "output_fraud = custIDnameFraud[['custID', 'fraudster']]\n",
    "print(output_fraud)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "de9c3295",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Milestone3 ##################\n",
    "#print(custID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "9edc7f76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#previous downloaded file format\n",
    "AcctInput = custID.copy()\n",
    "AcctInput['loginAcct'] = jpg_loginAcct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "d0305cfe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    custID  rightAcctFlag\n",
      "0     1083              0\n",
      "1     1137              0\n",
      "2     1207              0\n",
      "3     1240              0\n",
      "4     1389              0\n",
      "..     ...            ...\n",
      "15    1736              0\n",
      "16    1777              0\n",
      "17    1791              0\n",
      "18    1803              0\n",
      "19    1806              0\n",
      "\n",
      "[20 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "### left join input table and customerlist\n",
    "custIDname_verify = pd.merge(AcctInput, CustomerList, on='custID', how='left')\n",
    "\n",
    "# b=BankAcct.dtypes\n",
    "# print(b)\n",
    "# input csv\n",
    "BankAcct = pd.read_csv(\"./liveBankAcct.csv\")\n",
    "custIDname_verify=custIDname_verify.astype({\"loginAcct\":int})\n",
    "# a=custIDname_verify.dtypes\n",
    "# print(a)\n",
    "### left join with bankacct\n",
    "AcctName_verify = pd.merge(custIDname_verify, BankAcct, left_on='loginAcct', right_on='bankAcctID', how='left')\n",
    "\n",
    "###add conditional rightAcctFlag column\n",
    "def f(AcctName_verify):\n",
    "    if AcctName_verify['firstName_x']==AcctName_verify['firstName_y'] and AcctName_verify['lastName_x']==AcctName_verify['lastName_y']:\n",
    "        val = 1\n",
    "    else:\n",
    "        val = 0\n",
    "    return val\n",
    "AcctName_verify['rightAcctFlag'] = AcctName_verify.apply(f,axis=1)\n",
    "\n",
    "#FraudTestOnput.csv\n",
    "output_verify = AcctName_verify[['custID','rightAcctFlag']]\n",
    "print(output_verify)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "b04f03e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Milestone5 ##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "659b5ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#read startbalance & bankTransactions \n",
    "acctStBalan = pd.read_csv('./Milestone5Files/startBalance.csv')\n",
    "bankTrans = pd.read_csv('./Milestone5Files/bankTransactions.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "38ac9a39",
   "metadata": {},
   "outputs": [],
   "source": [
    "# left join loginAcct & startBalanceInfo\n",
    "acctStBalan = loginAcct.merge(acctStBalan, left_on = 'loginAcct', right_on='bankAcctID', how = 'left')\n",
    "# left join loginAcct & bankTransactions, append acctIDTrans to acctStBalanInfo\n",
    "acctIDTrans = loginAcct.merge(bankTrans, left_on = 'loginAcct', right_on='bankAcctID', how = 'left')\n",
    "\n",
    "acctIDTrans = acctIDTrans.rename({'transAmount': 'amt'}, axis =1)\n",
    "\n",
    "#append acctIDTrans to acctStBalanInfo\n",
    "acctsBalanInfo = acctStBalan.append(acctIDTrans, ignore_index = True)\n",
    "acctsBalanInfo = acctsBalanInfo[acctsBalanInfo.amt > 200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "fbf3455b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    bankAcctID    max_date second_max_date\n",
      "0       210966  2020-03-30      2020-02-18\n",
      "1       240040  2020-04-28      2020-04-14\n",
      "2       242432  2020-04-24      2020-04-17\n",
      "3       272572  2020-04-21      2020-04-14\n",
      "4       283946  2020-04-17      2020-04-03\n",
      "..         ...         ...             ...\n",
      "15      642059  2020-04-30      2020-04-15\n",
      "16      650818  2020-04-01      2020-03-02\n",
      "17      679739  2020-04-30      2020-03-31\n",
      "18      680022  2020-04-30      2020-04-16\n",
      "19      748223  2020-04-17      2020-04-03\n",
      "\n",
      "[20 rows x 3 columns]\n"
     ]
    }
   ],
   "source": [
    "second_max_date = acctsBalanInfo.sort_values([\"bankAcctID\",\"date\"], ascending=[1,0]).groupby(\"bankAcctID\").agg({\"date\":lambda x: x.shift(-1).values[0]}).reset_index()\n",
    "second_max_date.columns = second_max_date.columns.str.replace('date', 'second_max_date')\n",
    "max_date = acctsBalanInfo.groupby('bankAcctID')['date'].max().reset_index()\n",
    "max_date.columns = max_date.columns.str.replace('date', 'max_date')\n",
    "# left join second_max_date and max_date\n",
    "first_sec_max = max_date.merge(second_max_date, on = 'bankAcctID', how = 'left')\n",
    "print(first_sec_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "8845a33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pay_method = [\n",
    "    ['2020-04-15','2020-04-30','2020-05-15'], \n",
    "    ['2020-04-17','2020-05-17','2020-06-17'],\n",
    "    ['2020-04-20','2020-05-20','2020-06-20'],\n",
    "    ['2020-04-10','2020-04-24','2020-05-08'],\n",
    "    ['2020-04-17','2020-04-24','2020-05-01'],\n",
    "    ['2020-04-30','2020-05-30','2020-06-30'],\n",
    "    ['2020-04-13','2020-04-27', '2020-05-11'],\n",
    "    ['2020-04-15','2020-05-15','2020-06-15'],\n",
    "    ['2020-04-20','2020-04-27', '2020-05-04'],\n",
    "    ['2020-04-23','2020-04-30', '2020-05-07'],\n",
    "    ['2020-04-23','2020-05-23','2020-06-23'],\n",
    "    ['2020-04-22','2020-05-22','2020-06-22'],\n",
    "    ['2020-04-21', '2020-05-21','2020-06-21'],\n",
    "    ['2020-04-10','2020-05-10','2020-06-10'],\n",
    "    ['2020-04-15', '2020-04-29', '2020-05-13'],\n",
    "    ['2020-04-13', '2020-05-13','2020-06-13'],\n",
    "    ['2020-04-14', '2020-04-28', '2020-05-12'],\n",
    "    ['2020-04-21','2020-04-28', '2020-05-05'], \n",
    "    ['2020-04-22', '2020-04-29', '2020-05-06'], \n",
    "    ['2020-04-16', '2020-04-30', '2020-05-14'], \n",
    "    ['2020-04-20', '2020-04-30', '2020-05-10'], \n",
    "    ['2020-04-27','2020-05-27','2020-06-27'],\n",
    "    ['2020-04-16','2020-05-16','2020-06-16'],\n",
    "    ['2020-04-27', '2020-04-30', '2020-05-03'],\n",
    "    ['2020-04-10', '2020-04-17', '2020-04-24'], \n",
    "    #add\n",
    "    ['2020-04-14', '2020-04-27', '2020-04-24'], \n",
    "    ['2020-04-03', '2020-04-17', '2020-05-01'], \n",
    "    ['2020-03-02', '2020-04-01', '2020-05-01'], #not sure\n",
    "    ['2020-04-07', '2020-04-21', '2020-05-05'],\n",
    "    ['2020-03-23', '2020-04-13', '2020-05-04'],\n",
    "    ['2020-04-09', '2020-04-23', '2020-05-07'],\n",
    "    ['2020-03-31', '2020-04-15', '2020-04-30'], #not sure\n",
    "    ['2020-03-31', '2020-04-30', '2020-05-29'],#not sure\n",
    "    ['2020-04-06', '2020-04-20', '2020-05-04'],\n",
    "    ['2020-04-08', '2020-04-22', '2020-05-06'],\n",
    "    ['2020-03-06', '2020-04-06', '2020-05-06'],\n",
    "    ['2020-03-30', '2020-04-13', '2020-04-27'],\n",
    "    ['2020-04-01', '2020-04-08', '2020-04-15'],\n",
    "    ['2020-03-20', '2020-04-20', '2020-05-20'],\n",
    "    ['2020-04-08', '2020-04-15', '2020-04-22'],\n",
    "    \n",
    "    \n",
    "    ]\n",
    "pay_pattern=pd.DataFrame(pay_method, columns = ['second_max_date','max_date','date'])\n",
    "# print(pay_pattern)\n",
    "# print(type(pay_pattern))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "6606b2b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    bankAcctID    max_date second_max_date        date\n",
      "0       210966  2020-03-30      2020-02-18          NA\n",
      "1       240040  2020-04-28      2020-04-14  2020-05-12\n",
      "2       242432  2020-04-24      2020-04-17  2020-05-01\n",
      "3       272572  2020-04-21      2020-04-14          NA\n",
      "4       283946  2020-04-17      2020-04-03  2020-05-01\n",
      "..         ...         ...             ...         ...\n",
      "15      642059  2020-04-30      2020-04-15  2020-05-15\n",
      "16      650818  2020-04-01      2020-03-02  2020-05-01\n",
      "17      679739  2020-04-30      2020-03-31  2020-05-29\n",
      "18      680022  2020-04-30      2020-04-16  2020-05-14\n",
      "19      748223  2020-04-17      2020-04-03  2020-05-01\n",
      "\n",
      "[20 rows x 4 columns]\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "#Join first_sec_max and pay_pattern\n",
    "pred_result = first_sec_max.merge(pay_pattern, on = ['max_date','second_max_date'], how = 'left')\n",
    "#pd.set_option('display.max_rows', None)\n",
    "pd.options.display.max_rows = 10\n",
    "pred_result['date']=pred_result['date'].fillna('NA')\n",
    "print(pred_result)\n",
    "#count no-na\n",
    "print(20-pred_result['date'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "958d6fd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    custID       date1\n",
      "0     1608          NA\n",
      "1     1736  2020-05-12\n",
      "2     1207  2020-05-01\n",
      "3     1436          NA\n",
      "4     1791  2020-05-01\n",
      "..     ...         ...\n",
      "15    1702  2020-05-15\n",
      "16    1735  2020-05-01\n",
      "17    1137  2020-05-29\n",
      "18    1389  2020-05-14\n",
      "19    1777  2020-05-01\n",
      "\n",
      "[20 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "pred_result_bankAcctID=pred_result[['bankAcctID','date']]\n",
    "# left join loginAcct & startBalanceInfo\n",
    "AcctInput=AcctInput.astype({\"loginAcct\":int})\n",
    "pred_result_custID = pred_result_bankAcctID.merge(AcctInput, left_on = 'bankAcctID', right_on='loginAcct', how = 'left')\n",
    "output_date=pred_result_custID[['custID','date']]\n",
    "output_date.columns = ['custID','date1']\n",
    "print(output_date)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "a7fcc8c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "################## Milestone1 ##################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "5df862f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "import io\n",
    "import glob\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import uuid\n",
    "import requests\n",
    "from urllib.parse import urlparse\n",
    "from io import BytesIO\n",
    "# To install this module, run:\n",
    "# python -m pip install Pillow\n",
    "from PIL import Image, ImageDraw\n",
    "from azure.cognitiveservices.vision.face import FaceClient\n",
    "from msrest.authentication import CognitiveServicesCredentials\n",
    "from azure.cognitiveservices.vision.face.models import TrainingStatusType, Person, QualityForRecognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "7cade6aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # This key will serve all examples in this document.\n",
    "# KEY = \"10597337c80f4cb3abe3e458f655a0f5\"\n",
    "# # This endpoint will be used in all examples in this quickstart.\n",
    "# ENDPOINT = \"https://testingud20000.cognitiveservices.azure.com/\"\n",
    "# face_client = FaceClient(ENDPOINT, CognitiveServicesCredentials(KEY))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "342748f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# TARGET_NAME = './PythonDropbox/'\n",
    "# SOURCE_NAME = './identityPics-custID_PicID/'\n",
    "\n",
    "# def generateMap(target_names, souce_names):\n",
    "#     target_names = glob.glob(target_names+\"*\")\n",
    "#     target_names_map = {}\n",
    "#     for x in target_names:\n",
    "#         target_names_map[x.split('/')[-1]] = []\n",
    "\n",
    "#     souce_names = glob.glob(souce_names+\"*\")\n",
    "\n",
    "#     for souce in souce_names:\n",
    "#         souce = souce.split('/')[-1]\n",
    "#         cur = souce[0:4] + '.jpg';\n",
    "#         if cur in target_names_map:\n",
    "#             target_names_map[cur].append(souce)\n",
    "#     return target_names_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "90b1e137",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def detect_face():\n",
    "#     target_map = generateMap(TARGET_NAME, SOURCE_NAME)\n",
    "#     resultList = []\n",
    "#     for k, v in target_map.items():\n",
    "#         if len(v) <= 0:\n",
    "#             resultList.append(k+\":0\")\n",
    "#             continue\n",
    "#         target_id = use_api(TARGET_NAME+k)\n",
    "#         souce_ids = [use_api(SOURCE_NAME+x) for x in v]\n",
    "#         myflag = False\n",
    "#         for c in souce_ids:\n",
    "#             verify_result_same = face_client.face.verify_face_to_face(c, target_id)\n",
    "#             if verify_result_same.is_identical:\n",
    "#                 resultList.append(k+\":1\")\n",
    "#                 myflag = True\n",
    "#                 break\n",
    "#         if myflag == False: \n",
    "#             resultList.append(k+\":0\")\n",
    "#     return resultList\n",
    "\n",
    "# def use_api(name):\n",
    "#     image = open(name, 'r+b')\n",
    "#     detected_faces1 = face_client.face.detect_with_stream(image, detectionModel='deteion_03')\n",
    "#     source_image1_id = detected_faces1[0].face_id\n",
    "#     return source_image1_id\n",
    "\n",
    "\n",
    "# res_list = detect_face()\n",
    "# print(res_list)\n",
    "# print(target_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "241e16f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 253,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from data_processor import DataProcessor\n",
    "import pandas as pd\n",
    "data_processer = DataProcessor(\"dd\")\n",
    "data_processer.execute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "a77549d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    custID face\n",
      "0     1803    0\n",
      "1     1735    0\n",
      "2     1451    0\n",
      "3     1566    0\n",
      "4     1456    0\n",
      "..     ...  ...\n",
      "15    1736    0\n",
      "16    1083    0\n",
      "17    1207    0\n",
      "18    1240    0\n",
      "19    1390   NA\n",
      "\n",
      "[20 rows x 2 columns]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/_f/yw_fbxld3jd694p1y10917zr0000gn/T/ipykernel_33203/2980099271.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  output_face['custID']=output_face['custID'].astype(int)\n"
     ]
    }
   ],
   "source": [
    "people = data_processer.persons\n",
    "data = [[v.get_customer_id(), v.get_account_id(), v.fraud] for v in people.values()]\n",
    "#df = pd.DataFrame(data, columns = ['CustomerId', 'AccountId', 'verifiedId'])\n",
    "df = pd.DataFrame(data, columns = ['custID', 'AccountId', 'verifiedId'])\n",
    "df['face'] = np.where((df['verifiedId']==0), 'NA',0)\n",
    "output_face = df[['custID', 'face']]\n",
    "output_face['custID']=output_face['custID'].astype(int)\n",
    "\n",
    "# print(df)\n",
    "print(output_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f21965a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d87517",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "8b0c8a25",
   "metadata": {},
   "outputs": [],
   "source": [
    "################### join output_fraud, output_verify, output_date, ***output_face(milestone1)*** together"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "c3b3f4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    custID fraudster  rightAcctFlag       date1 face\n",
      "0     1083         0              0  2020-05-01    0\n",
      "1     1137         0              0  2020-05-29    0\n",
      "2     1207         0              0  2020-05-01    0\n",
      "3     1240         0              0  2020-05-13    0\n",
      "4     1389         0              0  2020-05-14   NA\n",
      "..     ...       ...            ...         ...  ...\n",
      "15    1736         0              0  2020-05-12    0\n",
      "16    1777         0              0  2020-05-01    0\n",
      "17    1791         0              0  2020-05-01    0\n",
      "18    1803         0              0  2020-05-11    0\n",
      "19    1806         0              0  2020-05-13    0\n",
      "\n",
      "[20 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "fraud_verify = output_fraud.merge(output_verify, on='custID',how = 'left')\n",
    "fraud_verify_date = fraud_verify.merge(output_date, on='custID',how = 'left')\n",
    "fraud_verify_date_face = fraud_verify_date.merge(output_face, on='custID',how = 'left')\n",
    "print(fraud_verify_date_face)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "f1782493",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    custID fraudster  rightAcctFlag       date1 face        date\n",
      "0     1083         0              0  2020-05-01    0  2020-05-01\n",
      "1     1137         0              0  2020-05-29    0  2020-05-29\n",
      "2     1207         0              0  2020-05-01    0  2020-05-01\n",
      "3     1240         0              0  2020-05-13    0  2020-05-13\n",
      "4     1389         0              0  2020-05-14   NA          NA\n",
      "..     ...       ...            ...         ...  ...         ...\n",
      "15    1736         0              0  2020-05-12    0  2020-05-12\n",
      "16    1777         0              0  2020-05-01    0  2020-05-01\n",
      "17    1791         0              0  2020-05-01    0  2020-05-01\n",
      "18    1803         0              0  2020-05-11    0  2020-05-11\n",
      "19    1806         0              0  2020-05-13    0  2020-05-13\n",
      "\n",
      "[20 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "#fraud_verify_date_face\n",
    "output_prep = fraud_verify_date_face.copy()\n",
    "output_prep['date'] = output_prep['date1']\n",
    "output_prep['date'] = np.where((output_prep['fraudster']=='NA') | (output_prep['rightAcctFlag']=='NA') | (output_prep['date1']=='NA') | (output_prep['face']=='NA'), 'NA',output_prep['date1'])\n",
    "print(output_prep)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "144d9958",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    loginID        date\n",
      "0      1083  2020-05-01\n",
      "1      1137  2020-05-29\n",
      "2      1207  2020-05-01\n",
      "3      1240  2020-05-13\n",
      "4      1389  2020-05-14\n",
      "..      ...         ...\n",
      "15     1736  2020-05-12\n",
      "16     1777  2020-05-01\n",
      "17     1791  2020-05-01\n",
      "18     1803  2020-05-11\n",
      "19     1806  2020-05-13\n",
      "\n",
      "[20 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "################## output csv ##################\n",
    "output = output_prep[['custID','date']]\n",
    "output.columns = ['loginID','date']\n",
    "print(output)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
